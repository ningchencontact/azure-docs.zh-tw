---
title: 評估模型:模組參考
titleSuffix: Azure Machine Learning service
description: 瞭解如何使用 Azure Machine Learning 服務中的 [評估模型] 模組來測量定型模型的精確度。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: xiaoharper
ms.author: zhanxia
ms.date: 05/06/2019
ms.openlocfilehash: 17263c8e7300f427b7d82aea65e1f83edf6d6fc4
ms.sourcegitcommit: 07700392dd52071f31f0571ec847925e467d6795
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 08/28/2019
ms.locfileid: "70128856"
---
# <a name="evaluate-model-module"></a>評估模型模組

本文描述適用于 Azure Machine Learning 服務的視覺化介面 (預覽) 模組。

使用此模組來測量已定型模型的精確度。 您提供的資料集包含從模型產生的分數, 而 [**評估模型**] 模組則會計算一組業界標準的評估度量。
  
 「**評估模型**」傳回的計量取決於您要評估的模型類型:  
  
-   **分類模型**    
-   **回歸模型**    



> [!TIP]
> 如果您是模型評估的新手, 我們建議使用 Dr 的影片系列。Stephen Elston, 做為 EdX 中[機器學習課程](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/)的一部分。 


有三種方式可以使用 [**評估模型**] 模組:

+ 在定型資料上產生分數, 並根據這些分數來評估模型
+ 在模型上產生分數, 但將這些分數與保留測試集的分數進行比較
+ 使用相同的資料集來比較兩個不同但相關模型的分數

## <a name="use-the-training-data"></a>使用定型資料

若要評估模型, 您必須連接包含一組輸入資料行和分數的資料集。  如果沒有其他可用的資料, 您可以使用原始資料集。

1. 將[評分模型](./score-model.md)的**評分資料集**輸出連接到**評估模型**的輸入。 
2. 按一下 [**評估模型**模組], 然後執行實驗以產生評估分數。

## <a name="use-testing-data"></a>使用測試資料

在機器學習中, 常見的案例是使用 Split 模組或[分割](./split-data.md)區[和範例](./partition-and-sample.md)模組, 將您的原始資料集劃分成定型和測試資料集。 

1. 將[評分模型](score-model.md)的**評分資料集**輸出連接到**評估模型**的輸入。 
2. 將包含測試資料之「分割資料」模組的輸出連接到「**評估模型**」的右側輸入。
2. 按一下 [**評估模型**模組], 然後選取 [**執行選取**的] 以產生評估分數。

## <a name="compare-scores-from-two-models"></a>比較兩個模型的分數

您也可以連接第二組分數來**評估模型**。  分數可能是具有已知結果的共用評估集, 或是來自不同模型的相同資料的一組結果。

這項功能很有用, 因為您可以輕鬆地比較相同資料上兩個不同模型的結果。 或者, 您可以比較兩個不同回合的分數與不同參數的相同資料。

1. 將[評分模型](score-model.md)的**評分資料集**輸出連接到**評估模型**的輸入。 
2. 將第二個模型的 [評分模型] 模組的輸出連接到 [**評估模型**] 的右側輸入。
3. 以滑鼠右鍵按一下 [**評估模型**], 然後選取 [**執行選取**的] 以產生評估分數。

## <a name="results"></a>結果

執行 [**評估模型**] 之後, 以滑鼠右鍵按一下模組, 然後選取 [**評估結果**] 以查看結果。 您可以：

+ 將結果另存為資料集, 以便更輕鬆地使用其他工具進行分析
+ 在介面中產生視覺效果

如果您將資料集連接到這兩個「**評估模型**」的輸入, 則結果會包含這兩個資料集的計量, 或兩種模型。
附加至左側埠的模型或資料會先顯示在報表中, 後面接著資料集的計量, 或在正確的埠上附加的模型。  

例如, 下圖表示兩個群集模型的結果比較, 這些模型是建立在相同的資料上, 但使用不同的參數。  

![AML&#95;Comparing2Models](media/module/aml-comparing2models.png "AML_Comparing2Models")  

因為這是叢集模型, 所以評估結果不同于您比較兩個回歸模型的分數, 或比較兩個分類模型。 不過, 整體的呈現方式相同。 

## <a name="metrics"></a>計量

本節說明針對支援搭配**評估模型**使用之特定模型類型所傳回的計量:

+ [分類模型](#bkmk_classification)
+ [回歸模型](#bkmk_regression)

###  <a name="bkmk_classification"></a>分類模型的計量

評估分類模型時, 會報告下列計量。 如果您比較模型, 則會依照您選取進行評估的計量排序。  
  
-   **精確度**會測量分類模型的健全狀況, 做為整體案例的實際結果比例。  
  
-   **精確度**是所有正面結果的 true 結果比例。  
  
-   **回想**是模型傳回的所有正確結果的分數。  
  
-   **F 分數**會計算為精確度的加權平均值, 並在0和1之間重新叫用, 其中理想的 F 分數值是1。  
  
-   **AUC**會測量在 y 軸上以真肯定繪製的曲線下的區域, 以及 X 軸上的誤報。 此度量很有用, 因為它提供單一數位, 可讓您比較不同類型的模型。  
  
- **平均記錄遺失**是用來表示錯誤結果之負面影響的單一分數。 其計算方式為兩個機率分佈之間的差異– true, 以及模型中的一個。  
  
- **定型記錄遺失**是單一分數, 代表透過隨機預測的分類器的優勢。 記錄遺失會藉由比較輸出的機率與標籤中的已知值 (真) 來測量模型的不確定性。 您想要將整個模型的記錄遺失降至最低。

##  <a name="bkmk_regression"></a>回歸模型的度量
 
針對回歸模型傳回的計量通常是設計來估計錯誤量。  如果觀察到和預測值之間的差異很小, 則會將模型視為適合資料的程度。 不過, 查看殘差的模式 (任何一個預測點和其對應的實際值之間的差異), 可以告訴您有關模型中潛在偏差的許多資訊。  
  
 系統會針對評估回歸模型回報下列計量。 當您比較模型時, 它們會依照您選取進行評估的度量來進行排序。  
  
- **平均絕對錯誤 (MAE)** 測量預測與實際結果之間的接近程度;因此, 分數越低越好。  
  
- **根平均平方誤差 (RMSE)** 會建立單一值, 以摘要說明模型中的錯誤。 藉由對差異進行求值, 計量會忽略過度預測和預測下的差異。  
  
- **相對絕對錯誤 (RAE)** 是預期和實際值之間的相對絕對差異;相對, 因為平均差異是除以算術平均值。  
  
- **相對平方誤差 (RSE)** 同樣地, 會將預測值的總平方誤差除以實際值的總平方誤差。  
  
- **Mean 零1錯誤 (MZOE)** 指出預測是否正確。  換句話說: `ZeroOneLoss(x,y) = 1`當`x!=y`為, 則為`0`, 否則為。
  
- **決定係數**(通常稱為 R<sup>2</sup>) 表示模型的預測能力是介於0和1之間的值。 零表示模型是隨機的 (不會說明任何內容);1表示有完美的調整。 不過, 請小心解釋 R<sup>2</sup>值, 因為低值可能完全正常, 且高值可能會有疑問。
  

## <a name="next-steps"></a>後續步驟

請參閱可用來 Azure Machine Learning 服務的[模組集合](module-reference.md)。 