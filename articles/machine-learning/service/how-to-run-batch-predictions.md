---
title: 對巨量資料執行批次預測
titleSuffix: Azure Machine Learning
description: 了解如何在 Azure Machine Learning 中使用批次推斷，以非同步方式來取得大量資料的推斷。 批次推斷可提供現成可用的平行處理功能，並針對巨量資料使用案例最佳化以實現高輸送量、射後不理的推斷。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: tutorial
ms.reviewer: trbye, jmartens, larryfr, vaidyas
ms.author: vaidyas
author: vaidya-s
ms.date: 11/04/2019
ms.custom: Ignite2019
ms.openlocfilehash: 62a2c3324df70c7ccdbbac273d314ff94cbb7b9a
ms.sourcegitcommit: 265f1d6f3f4703daa8d0fc8a85cbd8acf0a17d30
ms.translationtype: HT
ms.contentlocale: zh-TW
ms.lasthandoff: 12/02/2019
ms.locfileid: "74671571"
---
# <a name="run-batch-inference-on-large-amounts-of-data-by-using-azure-machine-learning"></a>使用 Azure Machine Learning 對大量資料執行批次推斷
[!INCLUDE [applies-to-skus](../../../includes/aml-applies-to-basic-enterprise-sku.md)]

在此操作說明中，您會了解如何使用 Azure Machine Learning 以非同步和平行的方式取得大量資料的推斷。 這裡所述的批次推斷功能屬於公開預覽版。 此預覽版能以高效能且高輸送量的方式產生推斷和處理資料。 其會提供現成可用的非同步功能。

透過批次推斷，即可直接將離線推斷擴充至大型機器叢集的數 TB 生產資料，進而提升生產力並獲得最佳成本。

在此操作說明中，您將了解下列工作：

> * 建立遠端計算資源。
> * 撰寫自訂推斷指令碼。
> * 建立[機器學習管線](concept-ml-pipelines.md)來註冊以 [MNIST](https://publicdataset.azurewebsites.net/dataDetail/mnist/) 資料集為基礎的預先定型影像分類模型。 
> * 使用此模型對 Azure Blob 儲存體帳戶中可用的影像範例執行批次推斷。 

## <a name="prerequisites"></a>必要條件

* 如果您沒有 Azure 訂用帳戶，請在開始前先建立一個免費帳戶。 試用[免費或付費版本的 Azure Machine Learning](https://aka.ms/AMLFree)。

* 如需引導式快速入門，但您還沒有 Azure Machine Learning 工作區或 Notebook 虛擬機器，請先完成[設定教學課程](tutorial-1st-experiment-sdk-setup.md)。 

* 若要管理您自己的環境和相依性，請參閱關於如何設定自有環境的[操作指南](how-to-configure-environment.md)。 在您的環境中執行 `pip install azureml-sdk[notebooks] azureml-pipeline-core azureml-contrib-pipeline-steps`，以下載必要的相依性。

## <a name="set-up-machine-learning-resources"></a>設定機器學習資源

下列動作會設定要執行批次推斷管線所需的資源：

- 建立資料存放區，並使其指向具有所要推斷影像的 Blob 容器。
- 將資料參考設定為批次推斷管線步驟的輸入和輸出。
- 設定計算叢集來執行批次推斷步驟。

### <a name="create-a-datastore-with-sample-images"></a>建立具有影像範例的資料存放區

從 `pipelinedata` 帳戶上的公用 Blob 容器 `sampledata` 取得 MNIST 評估集。 建立名稱為 `mnist_datastore` 的資料存放區，並使其指向此容器。 在下列 `register_azure_blob_container` 呼叫中，將 `overwrite` 旗標設定為 `True` 將會覆寫先前使用該名稱建立的任何資料存放區。 

您可以藉由提供您自己的 `datastore_name`、`container_name` 和 `account_name` 值，將此步驟變更為指向您的 Blob 容器。

```python
from azureml.core import Datastore
from azureml.core import Workspace

# Load workspace authorization details from config.json
ws = Workspace.from_config()

mnist_blob = Datastore.register_azure_blob_container(ws, 
                      datastore_name="mnist_datastore", 
                      container_name="sampledata", 
                      account_name="pipelinedata",
                      overwrite=True)
```

接著，將工作區的預設資料存放區指定為輸出資料存放區。 您會將其用於推斷輸出。

當您建立工作區時，預設會將[檔案儲存體](https://docs.microsoft.com/azure/storage/files/storage-files-introduction) 和 [Blob 儲存體](https://docs.microsoft.com/azure/storage/blobs/storage-blobs-introduction) 連結至工作區。 檔案儲存體是工作區的預設資料存放區，但您也可以使用 Blob 儲存體作為資料存放區。 如需詳細資訊，請參閱 [Azure 儲存體選項](https://docs.microsoft.com/azure/storage/common/storage-decide-blobs-files-disks)。

```python
def_data_store = ws.get_default_datastore()
```

### <a name="configure-data-inputs-and-outputs"></a>設定資料輸入和輸出

現在，您需要設定資料輸入和輸出，包括：

- 包含輸入影像的目錄。
- 預先定型的模型儲存所在的目錄。
- 包含標籤的目錄。
- 用於輸出的目錄。

`Dataset` 類別可用來在 Azure Machine Learning 中探索、轉換和管理資料。 此類別有兩種類型：`TabularDataset` 和 `FileDataset`。 在此範例中，您將使用 `FileDataset` 作為批次推斷管線步驟的輸入。 

> [!NOTE] 
> 批次推斷中的 `FileDataset` 支援目前僅限於 Azure Blob 儲存體。 

您也可以在自訂推斷指令碼中參照其他資料集。 例如，您可以藉由使用 `Dataset.register` 和 `Dataset.get_by_name`，而用此類別來存取指令碼中用於標記影像的標籤。

如需 Azure Machine Learning 資料集的詳細資訊，請參閱[建立和存取資料集 (預覽)](https://docs.microsoft.com/azure/machine-learning/service/how-to-create-register-datasets)。

`PipelineData` 物件可用來在管線步驟之間傳輸中繼資料。 在此範例中，您會將其用於推斷輸出。

```python
from azureml.core.dataset import Dataset

mnist_ds_name = 'mnist_sample_data'

path_on_datastore = mnist_blob.path('mnist/')
input_mnist_ds = Dataset.File.from_files(path=path_on_datastore, validate=False)
registered_mnist_ds = input_mnist_ds.register(ws, mnist_ds_name, create_new_version=True)
named_mnist_ds = registered_mnist_ds.as_named_input(mnist_ds_name)

output_dir = PipelineData(name="inferences", 
                          datastore=def_data_store, 
                          output_path_on_compute="mnist/results")
```

### <a name="set-up-a-compute-target"></a>設定計算目標

在 Azure Machine Learning 中，*計算* (或*計算目標*) 係指會在您機器學習管線中執行計算步驟的機器或叢集。 請執行下列程式碼來建立以 CPU 為基礎的 [AmlCompute](https://docs.microsoft.com/python/api/azureml-core/azureml.core.compute.amlcompute.amlcompute?view=azure-ml-py) 目標。

```python
from azureml.core.compute import AmlCompute, ComputeTarget
from azureml.core.compute_target import ComputeTargetException

# choose a name for your cluster
compute_name = os.environ.get("AML_COMPUTE_CLUSTER_NAME", "cpu-cluster")
compute_min_nodes = os.environ.get("AML_COMPUTE_CLUSTER_MIN_NODES", 0)
compute_max_nodes = os.environ.get("AML_COMPUTE_CLUSTER_MAX_NODES", 4)

# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6
vm_size = os.environ.get("AML_COMPUTE_CLUSTER_SKU", "STANDARD_D2_V2")


if compute_name in ws.compute_targets:
    compute_target = ws.compute_targets[compute_name]
    if compute_target and type(compute_target) is AmlCompute:
        print('found compute target. just use it. ' + compute_name)
else:
    print('creating a new compute target...')
    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,
                                                                min_nodes = compute_min_nodes, 
                                                                max_nodes = compute_max_nodes)

    # create the cluster
    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)
    
    # can poll for a minimum number of nodes and for a specific timeout. 
    # if no min node count is provided it will use the scale settings for the cluster
    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)
    
     # For a more detailed view of current AmlCompute status, use get_status()
    print(compute_target.get_status().serialize())
```

## <a name="prepare-the-model"></a>準備模型

[下載預先定型的影像分類模型](https://pipelinedata.blob.core.windows.net/mnist-model/mnist-tf.tar.gz)，然後將其解壓縮至 `models` 目錄。

```python
import os
import tarfile
import urllib.request

model_dir = 'models'
if not os.path.isdir(model_dir):
    os.mkdir(model_dir)

url="https://pipelinedata.blob.core.windows.net/mnist-model/mnist-tf.tar.gz"
response = urllib.request.urlretrieve(url, "model.tar.gz")
tar = tarfile.open("model.tar.gz", "r:gz")
tar.extractall(model_dir)
```

然後，向您的工作區註冊模型，使其可供遠端計算資源使用。

```python
from azureml.core.model import Model

# Register the downloaded model 
model = Model.register(model_path="models/",
                       model_name="mnist",
                       tags={'pretrained': "mnist"},
                       description="Mnist trained tensorflow model",
                       workspace=ws)
```

## <a name="write-your-inference-script"></a>撰寫推斷指令碼

>[!Warning]
>下列程式碼只是[筆記本範例](https://aka.ms/batch-inference-notebooks)所使用的範例。 請針對您的案例建立自己的指令碼。

指令碼「必須包含」  兩個函式：
- `init()`：請將此函式用於高成本或一般的準備，以進行後續的推斷。 例如，使用此函式將模型載入至全域物件。
-  `run(mini_batch)`：此函式會針對每個 `mini_batch` 執行個體來執行。
    -  `mini_batch`：批次推斷會叫用 run 方法，並將 list 或 Pandas 資料框架作為引數傳遞給方法。 min_batch 中的每個項目會是檔案路徑 (如果輸入是 FileDataset) 或 Pandas 資料框架 (如果輸入是 TabularDataset)。
    -  `response`：run() 方法應該傳回 Pandas 資料框架或陣列。 針對 append_row output_action，這些傳回的元素會附加至一般輸出檔案。 針對 summary_only，則會忽略元素的內容。 針對所有輸出動作，每個傳回的輸出元素會指出輸入迷你批次中一次成功的輸入元素推斷。 使用者應確保推斷結果中有足夠的資料可將輸入對應至推斷。 推斷輸出將會寫入至輸出檔案，而且不保證會按照順序，所以使用者應該在輸出中使用某個索引鍵以將其對應至輸入。

```python
# Snippets from a sample script.
# Refer to the accompanying digit_identification.py
# (https://aka.ms/batch-inference-notebooks)
# for the implementation script.

import os
import numpy as np
import tensorflow as tf
from PIL import Image
from azureml.core import Model


def init():
    global g_tf_sess

    # Pull down the model from the workspace
    model_path = Model.get_model_path("mnist")

    # Construct a graph to execute
    tf.reset_default_graph()
    saver = tf.train.import_meta_graph(os.path.join(model_path, 'mnist-tf.model.meta'))
    g_tf_sess = tf.Session()
    saver.restore(g_tf_sess, os.path.join(model_path, 'mnist-tf.model'))


def run(mini_batch):
    print(f'run method start: {__file__}, run({mini_batch})')
    resultList = []
    in_tensor = g_tf_sess.graph.get_tensor_by_name("network/X:0")
    output = g_tf_sess.graph.get_tensor_by_name("network/output/MatMul:0")

    for image in mini_batch:
        # Prepare each image
        data = Image.open(image)
        np_im = np.array(data).reshape((1, 784))
        # Perform inference
        inference_result = output.eval(feed_dict={in_tensor: np_im}, session=g_tf_sess)
        # Find the best probability, and add it to the result list
        best_result = np.argmax(inference_result)
        resultList.append("{}: {}".format(os.path.basename(image), best_result))

    return resultList
```

## <a name="build-and-run-the-batch-inference-pipeline"></a>建置並執行批次推斷管線

現在，您已備妥一切所需而可建置管線。

### <a name="prepare-the-run-environment"></a>準備執行環境

首先，為指令碼指定相依性。 當您稍後建立管線步驟時，將會用到這個物件。

```python
from azureml.core import Environment
from azureml.core.conda_dependencies import CondaDependencies
from azureml.core.runconfig import DEFAULT_GPU_IMAGE

batch_conda_deps = CondaDependencies.create(pip_packages=["tensorflow==1.13.1", "pillow"])

batch_env = Environment(name="batch_environment")
batch_env.python.conda_dependencies = batch_conda_deps
batch_env.docker.enabled = True
batch_env.docker.base_image = DEFAULT_GPU_IMAGE
batch_env.spark.precache_packages = False
```

### <a name="specify-the-parameters-for-your-batch-inference-pipeline-step"></a>指定批次推斷管線步驟的參數

`ParallelRunConfig` 是 Azure Machine Learning 管線內，適用於新引進批次推斷 `ParallelRunStep` 執行個體的主要設定。 您可以用此設定來包裝指令碼並設定必要參數，包括下列各項：
- `entry_script`：作為本機檔案路徑的使用者指令碼，將會在多個節點上平行執行。 如果 `source_directly` 存在，請使用相對路徑。 否則，使用可在機器上存取的路徑即可。
- `mini_batch_size`：傳遞至單一 `run()` 呼叫的迷你批次大小。 (選擇性；預設值為 `1`)。
    - 針對 `FileDataset`，這是最小值為 `1` 的檔案數目。 您可以將多個檔案結合成一個迷你批次。
    - 針對 `TabularDataset`，這是資料的大小。 範例值為 `1024`、`1024KB`、`10MB` 和 `1GB`。 建議值是 `1MB`。 請注意，`TabularDataset` 中的迷你批次絕對不會跨越檔案界限。 例如，如果您有各種大小的 .csv 檔案，最小檔案為 100 KB，最大檔案則為 10 MB。 如果您設定 `mini_batch_size = 1MB`，則系統會將大小小於 1 MB 的檔案視為一個迷你批次。 大小大於 1 MB 的檔案則會分割成多個迷你批次。
- `error_threshold`：處理期間應該忽略的記錄失敗數目 (針對 `TabularDataset`) 和檔案失敗數目 (針對 `FileDataset`)。 如果整個輸入的錯誤計數超過此值，作業便會停止。 錯誤閾值適用於整個輸入，而非適用於傳送至 `run()` 方法的個別迷你批次。 範圍為 `[-1, int.max]`。 `-1` 部分會指出要在處理期間忽略所有失敗。
- `output_action`：下列其中一個值會指出輸出的組織方式：
    - `summary_only`：使用者指令碼會儲存輸出。 `ParallelRunStep` 只會將輸出用於計算錯誤閾值。
    - `append_row`：針對所有輸入檔案，輸出檔案夾中只會建立一個檔案，並以直線分隔的方式附加所有輸出。 檔案名稱會是 parallel_run_step.txt。
- `source_directory`：資料夾的路徑，此資料夾包含要在計算目標上執行的所有檔案 (選擇性)。
- `compute_target`：只支援 `AmlCompute`。
- `node_count`：要用來執行使用者指令碼的計算節點數目。
- `process_count_per_node`：每個節點的處理序數目。
- `environment`：Python 環境定義。 您可以將其設定為使用現有 Python 環境，也可以設定用來進行實驗的暫存環境。 定義也會負責設定必要的應用程式相依性 (選擇性)。
- `logging_level`：記錄詳細程度。 增加詳細程度的值包括：`WARNING`、`INFO` 和 `DEBUG`。 預設值為 `INFO` (選擇性)。
- `run_invocation_timeout`：`run()` 方法叫用逾時 (以秒為單位)。 預設值為 `60`。

```python
from azureml.contrib.pipeline.steps import ParallelRunConfig

parallel_run_config = ParallelRunConfig(
    source_directory=scripts_folder,
    entry_script="digit_identification.py",
    mini_batch_size="5",
    error_threshold=10,
    output_action="append_row",
    environment=batch_env,
    compute_target=compute_target,
    node_count=4)
```

### <a name="create-the-pipeline-step"></a>建立管線步驟

使用指令碼、環境設定和參數來建立管線步驟。 指定您已附加至工作區的計算目標以作為指令碼的執行目標。 使用 `ParallelRunStep` 來建立批次推斷管線步驟，其採用下列所有參數：
- `name`：步驟的名稱，具有下列命名限制：唯一的、3 至 32 個字元，且 RegEx ^\[a-z\]([-a-z0-9]*[a-z0-9])?$。
- `models`：已在 Azure Machine Learning 模型登錄中註冊的零個或多個模型名稱。
- `parallel_run_config`：如先前所定義的 `ParallelRunConfig` 物件。
- `inputs`：一或多個單一類型的 Azure Machine Learning 資料集。
- `output`：對應至輸出目錄的 `PipelineData` 物件。
- `arguments`：傳遞至使用者指令碼的引數清單 (選擇性)。
- `allow_reuse`：在使用相同設定/輸入執行時，步驟是否應重複使用先前的結果。 如果此參數為 `False`，則在管線執行期間，一律會為此步驟產生新的執行。 (選擇性；預設值為 `True`)。

```python
from azureml.contrib.pipeline.steps import ParallelRunStep

parallelrun_step = ParallelRunStep(
    name="batch-mnist",
    models=[model],
    parallel_run_config=parallel_run_config,
    inputs=[named_mnist_ds],
    output=output_dir,
    arguments=[],
    allow_reuse=True
)
```

### <a name="run-the-pipeline"></a>執行管道

現在，請執行管線。 首先，使用工作區參考和您建立的管線步驟來建立 `Pipeline` 物件。 `steps` 參數是步驟的陣列。 在此案例中，批次評分只有一個步驟。 若要建置有多個步驟的管線，請在此陣列中依序放置步驟。

接下來，使用 `Experiment.submit()` 函式來提交管線以供執行。

```python
from azureml.pipeline.core import Pipeline
from azureml.core.experiment import Experiment

pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])
pipeline_run = Experiment(ws, 'digit_identification').submit(pipeline)
```

## <a name="monitor-the-batch-inference-job"></a>監視批次推斷作業

批次推斷作業需要很長的時間才能完成。 此範例會使用 Jupyter 小工具來監視進度。 您也可以使用下列方式來管理作業的進度：

* Azure Machine Learning Studio。 
* 來自 [`PipelineRun`](https://docs.microsoft.com/python/api/azureml-pipeline-core/azureml.pipeline.core.run.pipelinerun?view=azure-ml-py) 物件的主控台輸出。

```python
from azureml.widgets import RunDetails
RunDetails(pipeline_run).show()

pipeline_run.wait_for_completion(show_output=True)
```

## <a name="next-steps"></a>後續步驟

若要查看此程序的完整運作過程，請試試[批次推斷筆記本](https://aka.ms/batch-inference-notebooks)。 

如需管線的偵錯和疑難排解指引，請參閱[操作指南](how-to-debug-pipelines.md)。

[!INCLUDE [aml-clone-in-azure-notebook](../../../includes/aml-clone-for-examples.md)]

