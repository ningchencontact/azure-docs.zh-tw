---
title: 在 Azure Data Factory 的對應資料流程功能中設定接收轉換
description: 瞭解如何在對應的資料流程中設定接收轉換。
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/03/2019
ms.openlocfilehash: be2ab5605f7fa60ebb78493f714648d458e82a6c
ms.sourcegitcommit: 11265f4ff9f8e727a0cbf2af20a8057f5923ccda
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 10/08/2019
ms.locfileid: "72029233"
---
# <a name="sink-transformation-for-a-data-flow"></a>資料流程的接收轉換



在轉換資料流程之後，您可以將資料接收到目的地資料集。 在 [接收] 轉換中, 選擇目的地輸出資料的資料集定義。 當您的資料流程需要時，您可以擁有多個接收轉換。

若要考慮架構漂移和內送資料的變更，請將輸出資料接收到沒有在輸出資料集中定義之架構的資料夾。 您也可以在來源中選取 [**允許架構漂移**], 以考慮來源中的資料行變更。 然後自動對應接收器中的所有欄位。

![接收 索引標籤上的選項, 包括 自動對應 選項](media/data-flow/sink1.png "接收 1")

若要接收所有傳入的欄位, 請開啟 [**自動對應**]。 若要選擇要接收到目的地的欄位, 或變更目的地的欄位名稱, 請關閉 [**自動對應**]。 然後開啟 [**對應**] 索引標籤來對應輸出欄位。

![對應 索引標籤上的選項](media/data-flow/sink2.png "接收 2")

## <a name="output"></a>Output 
針對 Azure Blob 儲存體或 Data Lake Storage 接收類型，將已轉換的資料輸出到資料夾。 Spark 會根據接收器轉換所使用的資料分割配置，產生分割的輸出資料檔案。 

您可以從 [**優化**] 索引標籤設定資料分割配置。如果您想要 Data Factory 將您的輸出合併成單一檔案, 請選取 [**單一分割**區]。

![優化 索引標籤上的選項](media/data-flow/opt001.png "接收選項")

## <a name="field-mapping"></a>欄位對應
在接收轉換的 [**對應**] 索引標籤上, 您可以將左側的傳入資料行對應至右邊的目的地。 當您接收到檔案的資料流程時，Data Factory 一律會將新檔案寫入資料夾。 當您對應到資料庫資料集時，您會選擇要插入、更新、upsert 或刪除的資料庫資料表作業選項。

![對應 索引標籤](media/data-flow/sink2.png "接收")

在對應資料表中，您可以將多個資料行、取消多個資料行，或將多個資料列對應至相同的資料行名稱，以進行多重連結。

若要一律將一組傳入的欄位對應至目標, 並完全接受彈性的架構定義, 請選取 [**允許架構漂移**]。

![對應 索引標籤, 顯示對應至資料集中之資料行的欄位](media/data-flow/multi1.png "多個選項")

若要重設您的資料行對應, 請選取 [**重新對應**]。

![接收 索引標籤](media/data-flow/sink1.png "接收一個")

如果架構變更, 請選取 [**驗證架構**] 以使接收失敗。

選取 **[清除資料夾**] 以截斷接收資料夾的內容, 然後在該目的檔案夾中寫入目的地檔案。

## <a name="rule-based-mapping"></a>以規則為基礎的對應
當關閉自動對應時，您可以加入宣告以資料行為基礎的對應（固定對應）或以規則為基礎的對應。 以規則為基礎的對應可讓您撰寫具有模式比對的運算式。 

以![規則為基礎的對應](media/data-flow/rules4.png "規則為基礎的對應")

當您選擇以規則為基礎的對應時，您會指示 ADF 評估相符的運算式，以符合傳入模式規則並定義外寄功能變數名稱。 您可以新增欄位和以規則為基礎之對應的任意組合。 然後，ADF 會根據來源的傳入中繼資料，在執行時間產生功能變數名稱。 您可以在 debug 和使用 [資料預覽] 窗格期間, 查看所產生欄位的名稱。

模式比對的詳細資訊位於資料[行模式檔](concepts-data-flow-column-pattern.md)。

## <a name="file-name-options"></a>檔案名稱選項

設定檔案命名： 

   * **預設**：允許 Spark 根據部分預設值來命名檔案。
   * **模式**：輸入輸出檔案的模式。 例如,**貸款 [n]** 將會建立 loans1 .csv、loans2, 依此類推。
   * **每個資料分割**：為每個磁碟分割輸入一個檔案名。
   * **做為資料行中的資料**：將輸出檔設定為數據行的值。
   * **輸出至單一**檔案：使用此選項時，ADF 會將分割的輸出檔案結合成單一的命名檔案。 若要使用此選項，您的資料集應解析為資料夾名稱。 此外，請注意，此合併作業可能會根據節點大小而失敗。

> [!NOTE]
> 只有當您執行「執行資料流程」活動時，檔案作業才會啟動。 它們不會在資料流程的「資料流程」（Debug）模式中啟動。

## <a name="database-options"></a>資料庫選項

選擇資料庫設定：

![顯示 SQL 接收選項的 設定 索引標籤](media/data-flow/alter-row2.png "SQL 選項")

* **更新方法**：預設為允許插入。 如果您想要停止從來源插入新的資料列, 請清除 [**允許插入**]。 若要更新、upsert 或刪除資料列，請先加入 alter-row 轉換來標記這些動作的資料列。 
* **重新建立資料表**：在資料流程完成之前，請先卸載或建立目標資料表。
* **截斷資料表**：在資料流程完成之前，請先從目標資料表中移除所有資料列。
* **批次大小**：輸入一個數字，以將寫入填入多個區塊。 針對大型資料載入，請使用此選項。 
* **啟用預備**環境：當您將 Azure 資料倉儲當做接收資料集載入時，請使用 PolyBase。
* **前置和後置 SQL 腳本**：輸入將在（前置處理前）和之後（後置處理）資料寫入至您的接收資料庫之前執行的多行 SQL 腳本

![前置和後置 sql 處理腳本](media/data-flow/prepost1.png "sql 處理腳本")

> [!NOTE]
> 在 [資料流程] 中, 您可以指示 Data Factory 在目標資料庫中建立新的資料表定義。 若要建立資料表定義，請在接收轉換中設定具有新資料表名稱的資料集。 在 SQL 資料集的資料表名稱底下, 選取 [**編輯**], 然後輸入新的資料表名稱。 然後, 在 [接收] 轉換中, 開啟 [**允許架構漂移**]。 將 [匯**入架構**] 設定為 [**無**]。

![Sql 資料集設定，顯示編輯資料表名稱](media/data-flow/dataset2.png "SQL 架構")的位置

> [!NOTE]
> 當您更新或刪除資料庫接收中的資料列時，必須設定索引鍵資料行。 此設定可讓 alter row 轉換判斷資料手機連結庫（DML）中的唯一資料列。

## <a name="next-steps"></a>後續步驟
既然您已建立資料流程，請將「資料流程」[活動新增至您的管線](concepts-data-flow-overview.md)。
